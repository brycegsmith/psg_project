## CS4641 Summer 2022 Project - Sleep Stage Classification

### Infographic
![Infographic](https://github.com/brycegsmith/psg_project/blob/gh-pages/images/infographic.png)

### Introduction
Sleep is an important physiological process directly correlated with physical health, mental well-being, and chronic disease risk. Unfortunately, nearly 70 million Americans suffer from sleep disorders.<sup>1</sup> The most effective measurement of sleep quality to date is collecting polysomnography (PSG) data in a sleep laboratory and measuring the duration of sleep stages. However, sleep studies are expensive, time-consuming, and inaccessible to the majority of the population. Wearables have attempted to use heart rate data and machine learning algorithms to predict sleep stage, but suffer from low accuracy.<sup>2</sup> We intend to create a machine learning model for the automatic classification of sleep stages using a minimum viable subset of biosignals from PSG data.

### Methodology
#### Dataset
Our data source is the CAP Sleep Database on PhysioNet.<sup>3</sup> It contains PSG recordings for 108 individuals; each waveform has over 10 channels including EEGs (brain), EMGs (muscle), ECGs (heart), EOGs (eyes), and SPO2 (respiration) signals.<sup>4</sup> From each voltage waveform we extracted numerical measurements taken every two milliseconds. Additionally, for each individual, a text file provides labeled sleep stages every epoch (30 second interval) along with age, gender, and sleep disease information. After data preparation and feature extraction for all individuals, there were ~100,000 data points (~900 epochs for each individual) and ~30 features with at least one extracted feature from each biosignal. The target values are discrete sleep stages (Wake, REM, NREM 1-4). An overview of the distribution of sleep stages for all individuals in the dataset is shown below.

<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/sleep_stage_distribution.png" width="400" height="400">

#### Data Preparation
To begin, data was cleaned by combining the metadata in each individual's text file with their raw sensor measurements. Categorical data (e.g., sleep disorder) was converted to numerical form by dummy encoding.

Next, due to physiological variability between PSG subjects and many of the recordings being taken years apart, there is high variability between the subjects' baseline values. For example, the baseline ECG level for some subjects is significantly higher than others, due to factors like physiological differences and electrode connection. These differences in baselines are unique to each subject but persist through the entire recording. This was remedied by centering each individuals’s data by subtracting the mean of each of their features before combining their data with the rest of the subjects’ data.

Outliers were detected in the dataset using the Local Outlier Factor (LOF) method. This algorithm considers if a point is an outlier among its nearest neighbors, as opposed to considering the point in relation to the entire dataset. Thus, extreme outliers due to recording errors are removed, but expected outliers, such as spikes in muscle activity are not removed. For example, when heart beats are overrun by noise due to recording abnormalities, certain heart rate metrics, such as the low frequency change in heart rate can spike (often multiple orders of magnitude higher than expected). Such outliers were detected and removed based on the LOF method. Other statistical outliers, such as those due to spikes in EMG (muscle) activity are not removed using this method, which is advantageous because this type of outlier is a valid measurement that can be used to detect motion during sleep, often associated with REM and Wake sleep stages.

Finally, we applied robust scaling to our dataset using the interquartile range. We opted for robust scaling over standard scaling due to concerns regarding the effect of outliers on our dataset. The Box Cox Transformation was used to standardize all features to a normal distribution.

#### Feature Engineering
Feature extraction methods for each type of signal from the PSG data are described:
* __EEG__: EEG (electroencephalogram) is a technique used to detect electrical activity in the brain. Manual sleep stage classification is largely dependent on the fraction of brain waves with specific frequencies (e.g., delta waves with a frequency of 1 - 4 Hz) and secondary time-domain features. In our dataset, available EEG signals differ slightly between individuals, but broadly follow the International 10-20 System. Extensive literature exists on useful EEG features, so a subset of suggested features were selected. First, the time-domain EEG signal was decomposed into the frequency-domain using Welch’s method (see image below), and the power of each frequency band of each brain wave was computed. Second, multiple entropy-based metrics (i.e., metrics conveying the amount of information given by a signal) were computed. Finally, miscellaneous more sophisticated time-domain metrics (e.g., Petrosian fractal dimension) were calculated. In total, thirteen unique features were computed using the provided EEG signals. All EEG features were averaged across each individual’s EEG channels.
<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/eeg_report_image.png" width="450" height="300">

* __ECG & PPG__: ECG (electrocardiogram) and PPG (photoplethysmogram) are two methods used to record heart beats during the sleep studies. First, Python's hearty library was used to detect heart beats (see image below). Once heart beats were located, heart rate could be calculated. Beyond heart rate, an informative set of metrics consist of those that quantify variation in heart rate. The root mean square of the differences in time between adjacent heart beats (RMSSD) is one measure of heart rate variability, which is useful in our application because it can be meaningfully calculated over short time periods, such as 30 second epochs. Heart rate changes in the frequency domain, specifically “low frequency” changes in (0.04-0.15Hz) and “high frequency” changes (0.15-0.5 Hz) have been observed to vary with sleep stage, so these were also applied using the implementation in the heartpy library.
<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/ecg_report_image.png" width="450" height="300">

* __EMG__ - EMG (electromyography) is a method for measuring electrical activity of muscles. The main metric used to quantify the EMG activity was energy, calculated as the sum of squared differences between each point and the sample mean, divided by the number of samples. Progression into deeper stages of sleep is typically correlated with a decrease in muscle tone, which corresponds to a decrease in baseline EMG energy, but REM sleep is also associated with brief spikes in muscle activity (see image below). To capture these transient spikes in EMG energy that were “averaged out” over an entire 30 second epoch, a moving average with a five second window was applied over each second, and the average of the five highest windows was recorded within each 30 second epoch.
<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/emg_report_image.png" width="450" height="300">

* __EOG__: EOG (electrooculography) is used to detect activity within the human eye. One study aimed at Human-Computer Interaction applications mentioned a few useful features that were extracted from EOG signals, including: Maximum Peak Amplitude, which measures the maximum positive amplitude, Maximum Valley Amplitude, which measures the maximum negative amplitude, Area Under Curve, which is a summation of the absolute values of amplitude under positive and negative curves, and Signal Variance. All of these metrics were calculated within each epoch. Another study that focused specifically on sleep staging estimated the Power Spectrum for the EOG signal and calculated the Energy Content Band by integrating this function over the frequency range 0.35-0.5 Hz, where REM activity is concentrated. Using a Welch method to estimate the power spectrum, we calculated the Energy Content Band for each epoch.

* __SAO2__: SAO2 (or SPO2) refers to a blood-oxygen saturation reading which indicates the percentage of hemoglobin molecules that are saturated with oxygen. Readings can vary from 0 to 100% . Normal reading will range from 94% to 100%. Literature suggests readings below 50% are artifacts. Related literature to sleep staging using oximetry data engineered features by taking the peaks of each time period and the percentage of time spent above a certain threshold. We followed suit with our data by taking the maximum of each epoch and the percentage of time spent above 70%, 80%, and 90% oxygen saturation by epoch. In addition, we included the average oxygen saturation of each epoch.

#### Feature Selection
After feature extraction, the correlation and mutual information methods were used to eliminate unnecessary features.
* __Correlation Method__: Correlated features were detected and removed using the method proposed by Kuhn and Johnson. This method involves first calculating a correlation matrix for the data. Then, correlations are assessed pairwise (see image below). For any pair of features with a correlation above a set threshold (0.8 was used here), the feature in this pair with the larger average correlation between itself and every other feature was removed. This method eliminated 13 features.
<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/correlation_matrix.png" width="450" height="450">

* __Mutual Information Method__: After using the correlation method, we calculated the normalized mutual information between each feature and the sleep stages (target values) and defined four feature sets: the top 5, 10, 20, and 30 features with the greatest normalized mutual information values. As of this point, only the top 5 and top 10 sets have been evaluated by unsupervised learning, but we may incorporate use of the other two sets as we move into supervised learning.

#### Dimensionality Reduction
After feature selection, two methods were employed to reduce the dimensionality of data - Principal Component Analysis (PCA) and T-Distributed Stochastic Neighbor Embedding (TSNE).  Broadly, PCA linearly transforms combinations of features such that variance is maximized along each principal component (i.e., axis). TSNE is a more sophisticated dimensionality reduction  technique that is able to account for nonlinear features in data. Both techniques were employed on the four feature groups (i.e., top 5, 10, 20, & 30 features) and were used to reduce to 1, 2, and 3 components. An example of dimensionality reduction when reducing the top 10 features to 3 principal components using PCA is provided below.

<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/dimensionality_reduction.png" width="450" height="450">

#### Unsupervised Learning
Following dimensionality reduction, we applied several unsupervised learning methods to our data, including K-Means, GMM, and DBSCAN. To determine the quality of our clustering, we used the external measures of homogeneity, F1 score, normalized mutual information, Rand Statistic, and Fowlkes-Mallows measure. The sleep stages were taken as the “ground-truth” assignments, and each cluster was assigned a sleep stage based on the sleep stage of the majority of points in that cluster. We defined the “predicted” label of a point as the sleep stage of the cluster that it was assigned to.
* __K-Means__: First, K-Means was applied to our dataset via the sklearn implementation. As K-Means is notoriously sensitive to outliers, we expected suboptimal results. Thus, we explored similar methods to K-Means such as K-Medians and K-Medoids which are both more resistant to outliers. K-Means gave the baseline behavior while K-Medoids was chosen as it was the most outlier resistant due to the nature of cluster center selection. We utilized the elbow method and found that 3 clusters was optimal for K-Means & K-Medoids (see image below). It should be noted that 5 clusters is expected for our dataset as it would capture each stages of sleep. Thus, we ran the K-Means & K-Medoids on both 3 and 5 clusters. The 5 cluster models consistently gave better performances by all metrics.
<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/kmeans_plot.png" width="450" height="300">

* __GMM__: PLACEHOLDER

* __DBSCAN__: DBSCAN was applied using the implementation in the sklearn package. The critical parameters to set for the algorithm are epsilon, or the maximum radius of a neighborhood around a point, and MinPts, the minimum number of points required to be in a point’s epsilon neighborhood for that point to be considered a core point. The starting value of MinPts was determined based on the dimensionality of the data being clustered, using the rule of thumb that in noisy datasets, a MinPts of 2xD is often appropriate. Epsilon was calculated using the distance to the 4 nearest neighbors of each point (see image below). These distances were sorted and plotted, yielding a graph that shows a flat region followed by a sharp increase in distance to outliers. A starting value of epsilon was selected as a value in the flat region of this graph, and it was adjusted further by steps of 0.1 to increase the clustering metrics.
<img src="https://github.com/brycegsmith/psg_project/blob/gh-pages/images/dbscan_plot.png" width="450" height="300">

### Results
#### Feature Selection
The feature engineering and selection process discussed in the Methodology section was followed. As discussed, we selected the top 5, 10, 20, and 30 features and consider these sets separate for dimensionalityu reduction & unsupervised learning tasks. As an example, the image below shows the original 37 features being reduced to a set of the 30 features with the lowest correlation and highest mutual information.

PLACEHOLDER FOR FEATURE SELECTION IMAGE

#### Dimensionality Reduction
Again, the dimensionality reduction process using PCA and TSNE described in the Methodology section was followed. As an example, the results of PCA and TSNE reducing the Top 10 feature set to 3 components is shown in the image below. Similar visualizations were used to evaluate the performance of reduction to 1 and 2 components

PLACEHOLDER FOR DIMENSIONALITY REDUCTION IMAGE

#### Unsupervised Learning
After dimensionality reduction, K-Means, GMM, and DBSCAN were implemented on data according to the process outlined in the Methodology section. All of the algorithms performed best on the Top 10 feature sets, so only these results are provided. Although each algorithm was applied to each number of reduced components, only the best results are shared: K-Means (3rd & 4th component), GMM (PLACEHOLDER), and DBSCAN (3 Components). The external quality measures for the best result of each algorithm are provided in the bar plot below.

PLACEHOLDER FOR BEST KMEANS

PLACEHOLDER FOR BEST GMM

PLACEHOLDER FOR BEST DBSCAN

PLACEHOLDER FOR BARPLOT

### Discussion
#### Feature Engineering
There was high correlation among features within the same domain, especially EEG and EOG. For example, the petrosian and perm_entropy were the two most correlated metrics in the dataset because ….. The EOG metrics AUC (area under curve) and STD (standard deviation) were also closely correlated (correlation = 0.99) because AUC is the sum of the absolute values of individual voltage values in an epoch, so when AUC is higher, this indicates that there were more spikes in the EOG signal, causing the measurements to be further spread out overall. Similarly, two EMG metrics were used to measure EMG energy, which corresponds to muscle activity. One metric was an average EMG energy across an entire 30 second epoch, while the other was generated using a moving average with a 5 second window and then averaging the five highest 5 second periods. Although this second metric is more sensitive to spikes in EMG activity, across most epochs, it was very closely correlated with the average across the entire epoch (correlation = 0.97). As a whole, collinearity between features in this dataset can be explained by similarity in the feature extraction calculations used to generate metrics for the same signal type. These closely correlated features do not add significant insights to the model, so they can be removed to simplify the model. Beyond simplification, removing these correlated features within signal domains can improve the performance of later algorithms, such as PCA, by reducing imbalanced impacts on variance due to the number of features used for each type of signal.

Due to the high correlation between features within these domains, most of the features removed via our average correlation threshold were EEG and EOG features. We selected different sets of features with the top 5-30 normalized mutual information values with sleep stages for comparison purposes, since one of our project goals is determining a minimum viable subset of signals that can be used for accurate predictions. The features that had the lowest mutual information with sleep stages were Oxygen Saturation metrics, which is surprising given that breathing rate is known to decrease during deep sleep. We applied two stages of feature extraction in order to avoid issues with high-dimensional data like overfitting and distorted distance calculations in clustering. For example, the EMG metrics for the 5 second moving average and the 30 second epoch average were closely correlated (correlation = 0.97), so the moving 5 second average was removed because of the two metrics, it had a higher average correlation across all other features (average correlation = 0.3418). From there the EMG epoch average moved on to the mutual information feature selection step where it was removed from the set of “Top 5” features because it had the seventh highest mutual information with sleep stage.

#### Dimensionality Reduction
We investigated two dimensionality reduction algorithms, PCA and TSNE. In our results from PCA, outliers cause variance to be highly concentrated in the first principal component, leading to a tight distribution of data points in others. This issue becomes more apparent when we increase the dimensionality of the dataset, as evidenced by comparing the PCA results from the top 5 and top 10 feature sets. When we examine the target values of points across the entire first principal component in figure PLACEHOLDER, we see that most are in the “awake” stage since most of the spread-out points correspond to spikes in signals, such as muscle activity, which are most common when someone is awake.

#### Unsupervised Learning
Figure PLACEHOLDER shows the distribution of target values in our dataset. Based on the pie chart, the most frequent sleep stage label in our data appears to be NREM stage 2, but other stages like W (awake) and NREM stage 4 also comprise significant proportions. The spread of the class distribution here may contribute to poor results with our unsupervised learning methods. Since NREM stage 2 is the most prevalent sleep stage, most clusters will likely be assigned NREM stage 2 as well based on our definition. This means the predicted label of points in those clusters will also be NREM stage 2, but there is still a significant likelihood that a good portion of these points correspond to other sleep stages. 

Figure PLACEHOLDER shows the overall EOG energy content band data before Box-Cox transformation. EOG energy content band has one of the highest normalized mutual information scores with sleep stage labels, making it an important feature, and it reflects the extreme right skewness that most other features in our dataset exhibit. However, based on Figure PLACEHOLDER, we see that the Box-Cox transformation makes the distribution significantly more normal-shaped. Standardizing the shape of all features through Box-Cox transformation allows the data to be more balanced and reduces the impact of outliers.

For the purposes of this project, since we are looking at the accuracy of predicting sleep stage, supervised metrics using target values as “ground truth” is the most logical method of evaluating the quality of our clustering. The use of internal measures is not useful unless each cluster clearly corresponds to a distinct sleep stage, which was not the case.

All of our clustering algorithms run into issues due to the tight distribution of points in reduced dimensionality. Based on Figures 3-10, after running PCA or TSNE, the data looks very compact, with a lot of overlap between points corresponding to different sleep stages. As mentioned earlier, periodic outliers are common in our data, which can explain the fact that K-means had the poorest performance since it is especially sensitive to outliers. Some of the sleep stage clusters also appear to have highly irregular shapes, which is difficult for K-means to categorize.

Sleep stage prediction seems to be more tailored towards supervised learning methods. Most machine learning projects on sleep staging have gone directly to supervised learning algorithms with great accuracy. Part of our objective in applying unsupervised learning was to take a novel approach and evaluate the viability of unsupervised learning methods for this problem. Assigning each cluster the “majority” sleep stage is not an accurate way to summarize clusters since, as evidenced by the dimensionality reduction plots, there is significant overlap between data points with different sleep stage labels. Another potentially significant issue is that there is not enough distinction between different NREM stages. Machine learning projects that deal with sleep staging often focus on classifying awake, REM, and NREM sleep since there is a lot of overlap in the metrics corresponding to the different stages of NREM sleep, which are often difficult to distinguish based on metrics extracted from PSG data. Additionally, the proportion of individual NREM sleep stages in our data is significantly uneven, as evidenced by figure PLACEHOLDER. The significant overlap between data points from different sleep stages may be attributable to our pooling of individuals with different diseases. We hope to investigate this further as we proceed into the supervised learning portion, but our initial analysis indicates that when we examine the spread of data for each sleep stage for individuals without any sleep diseases, there seems to be less overlap compared to when all the individuals are combined. 

### References
1. Malekzadeh M, Hajibabaee P, Heidari M, Berlin B. Review of Deep Learning Methods for Automated Sleep Staging. 2022:0080-0086.
2. de Zambotti M, Goldstone A, Claudatos S, Colrain IM, Baker FC. A validation study of Fitbit Charge 2™ compared with polysomnography in adults. Chronobiology International. 2018/04/03 2018;35(4):465-476. doi:10.1080/07420528.2017.1413578
3. Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220 [Circulation Electronic Pages; http://circ.ahajournals.org/content/101/23/e215.full]; 2000 (June 13).
4. Terzano MG, Parrino L, Sherieri A, et al. Atlas, rules, and recording techniques for the scoring of cyclic alternating pattern (CAP) in human sleep. Sleep Med. Nov 2001;2(6):537-53. doi:10.1016/s1389-9457(01)00149-6
5. Li X, Ling SH, Su S. A Hybrid Feature Selection and Extraction Methods for Sleep Apnea Detection Using Bio-Signals. Sensors (Basel). 2020;20(15):4323. doi:10.3390/s20154323
6. Spiewak C, Islam R, Zaman A-U, Rahman MH. A Comprehensive Study on EMG Feature Extraction and Classifiers. Open Access Journal of Biomedical Engineering and Biosciences. February 07, 2018 2018;1(1)doi:http://dx.doi.org/10.32474/OAJBEB.2018.01.000104
7. Rodríguez-Sotelo JL, Osorio-Forero A, Jiménez-Rodríguez A, Cuesta-Frau D, Cirugeda-Roldán E, Peluffo D. Automatic Sleep Stages Classification Using EEG Entropy Features and Unsupervised Pattern Analysis Techniques. Entropy. 2014;16(12):6573-6589.
8. Amin HU, Mumtaz W, Subhani AR, Saad MNM, Malik AS. Classification of EEG Signals Based on Pattern Recognition Approach. Methods. Frontiers in Computational Neuroscience. 2017-November-21 2017;11doi:10.3389/fncom.2017.00103
9. Huang C, Lin C, Yang W, Ko L, Liu S, Lin C. Applying the fuzzy c-means based dimension reduction to improve the sleep classification system. 2013:1-5.
10. Rodríguez-Sotelo JL, Peluffo-Ordoñez D, Cuesta-Frau D, Castellanos-Domínguez G. Unsupervised feature relevance analysis applied to improve ECG heartbeat clustering. Computer Methods and Programs in Biomedicine. 2012/10/01/ 2012;108(1):250-261. doi:https://doi.org/10.1016/j.cmpb.2012.04.007
11. Satapathy S, Loganathan D, Kondaveeti HK, Rath R. Performance analysis of machine learning algorithms on automated sleep staging feature sets. CAAI Transactions on Intelligence Technology. 2021;6(2):155-174. doi:https://doi.org/10.1049/cit2.12042
